{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Giorgio Mendoza\n",
        "\n",
        "#CS539-F23-F02\n",
        "\n",
        "#Dr. J. Sethi\n",
        "\n",
        "#Lab: Week 8: Hypothesis Testing"
      ],
      "metadata": {
        "id": "3g7fMNqRlx-9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_tyOXKH6Ap2"
      },
      "source": [
        "# Lab_3-3: Hypothesis Testing\n",
        "This assignment requires more individual learning than previous assignments - you are encouraged to check out the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) to find functions or methods you might not have used yet, or ask questions on [Stack Overflow](http://stackoverflow.com/) and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff.\n",
        "\n",
        "Definitions:\n",
        "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
        "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
        "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
        "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
        "\n",
        "**Hypothesis**: University towns have their mean housing prices less affected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom: `price_ratio=quarter_before_recession/recession_bottom`\n",
        "\n",
        "The following data files are available for this assignment:\n",
        "\n",
        "* From the [Zillow research data site](http://www.zillow.com/research/data/), there is housing data for the United States. In particular, the datafile for [all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv), `City_Zhvi_AllHomes.csv`, has median home sale prices at a fine grained level.\n",
        "* From the Wikipedia page on college towns, there is a list of [university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) which has been copied and pasted into the file `university_towns.txt`.\n",
        "* From the Bureau of Economic Analysis, US Department of Commerce, the [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file `gdplev.xls`. For this lab, only look at GDP data from the first quarter of 2000 onward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xTyhBTy6Ap9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KxXAjdP6AqA"
      },
      "source": [
        "Each function in this assignment below is worth 10%, with the exception of `run_ttest()`, which is worth 50%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp1CF1-N6AqB"
      },
      "outputs": [],
      "source": [
        "# Use this dictionary to map state names to two letter acronyms\n",
        "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7-S3ME16AqB"
      },
      "source": [
        "## Question 0\n",
        "\n",
        "Let's get the list of university towns first:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def get_list_of_university_towns():\n",
        "    '''Returns a DataFrame of towns and the states they are in from the university_towns.txt list.\n",
        "    The format of the DataFrame should be: DataFrame([[\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Ypsilanti\"]], columns=[\"State\", \"RegionName\"])\n",
        "\n",
        "    The following cleaning needs to be done:\n",
        "    1. For \"State\", removing characters from \"[\" to the end.\n",
        "    2. For \"RegionName\", when applicable, removing every character from \"(\" to the end.\n",
        "    3. Depending on how you read the data, you may need to remove newline character '\\n'.\n",
        "    '''\n",
        "\n",
        "    university = []\n",
        "\n",
        "    file_path = '/content/drive/MyDrive/Colab Notebooks/university_towns.txt'\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        state = None\n",
        "        region = None\n",
        "\n",
        "        for line in file:\n",
        "            index = line.find('[edit]')\n",
        "            if index > 0:\n",
        "                state = line[0:index].strip()  # Extract the state\n",
        "            else:\n",
        "                index = line.find('(')\n",
        "                if index != -1:\n",
        "                    region = line[0:index].strip()  # Extract the region\n",
        "                else:\n",
        "                    region = line.strip()\n",
        "\n",
        "                if state is not None and region is not None:\n",
        "                    new_row = {'State': state, 'RegionName': region}\n",
        "                    university.append(new_row)\n",
        "\n",
        "    university_df = pd.DataFrame(university, columns=[\"State\", \"RegionName\"])\n",
        "    return university_df\n",
        "\n",
        "# Call the function to get the DataFrame\n",
        "university_towns_df = get_list_of_university_towns()\n",
        "print(university_towns_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IhsGbBvyqQMT",
        "outputId": "db7023de-e0cf-4efa-cc44-1bfa91d0e30c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "         State     RegionName\n",
            "0      Alabama         Auburn\n",
            "1      Alabama       Florence\n",
            "2      Alabama   Jacksonville\n",
            "3      Alabama     Livingston\n",
            "4      Alabama     Montevallo\n",
            "..         ...            ...\n",
            "512  Wisconsin    River Falls\n",
            "513  Wisconsin  Stevens Point\n",
            "514  Wisconsin       Waukesha\n",
            "515  Wisconsin     Whitewater\n",
            "516    Wyoming        Laramie\n",
            "\n",
            "[517 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOhYNNAF6AqD"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Lets' check the year and quarter of the recession start time next:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        " #Returns the year and quarter of the recession start time as a string value in a format such as 2005q3\n",
        "def get_recession_start():\n",
        "    my_gdp = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/gdplev.xls', skiprows=219)\n",
        "    # get YearQuarter & GDP\n",
        "    my_gdp = my_gdp.iloc[:, [4, 6]]\n",
        "    my_gdp.columns = ['Quarter', 'GDP']\n",
        "    for i in range(2, len(my_gdp)):\n",
        "      # Check if the GDP in the current quarter is lower than the GDP in the previous quarter\n",
        "      # and if the GDP in the previous quarter is lower than the GDP two quarters ago.\n",
        "      # checks potential recession when both criteria are met.\n",
        "        if (my_gdp.iloc[i - 2, 1] > my_gdp.iloc[i - 1, 1]) and (my_gdp.iloc[i - 1, 1] > my_gdp.iloc[i, 1]):\n",
        "            startDate = my_gdp.iloc[i - 3, 0]\n",
        "    return startDate\n",
        "\n",
        "recession_start = get_recession_start()\n",
        "print(recession_start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pDskbP7RpL8S",
        "outputId": "335c0798-adda-432b-a580-e48e3345ba0e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2008q3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dXoyYl-6AqE"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Let's also get the year and quarter of the recession end time:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "    #Returns the year and quarter of the recession end time as a string value in a format such as 2005q3\n",
        "def get_recession_end():\n",
        "    my_gdp = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/gdplev.xls', skiprows=219)\n",
        "    # get YearQuarter & GDP\n",
        "    my_gdp = my_gdp.iloc[:, 4:6]\n",
        "    my_gdp.columns = ['Quarter', 'GDP']\n",
        "    recStart = get_recession_start()\n",
        "    recStartIndex = my_gdp.index[my_gdp['Quarter'] == recStart].tolist()[0]\n",
        "    for i in range(recStartIndex + 1, len(my_gdp)):\n",
        "       # Check if GDP in current quarter is higher than GDP in previous quarter\n",
        "       # and if GDP in previous quarter is higher than GDP two quarters ago.\n",
        "        if (my_gdp.iloc[i - 2, 1] < my_gdp.iloc[i - 1, 1]) and (my_gdp.iloc[i - 1, 1] < my_gdp.iloc[i, 1]):\n",
        "           # Return year and quarter of GDP data for current quarter.\n",
        "         return my_gdp.iloc[i, 0]\n",
        "\n",
        "recEnd = get_recession_end()\n",
        "print(recEnd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KuHNURkfsVkf",
        "outputId": "f1209d6a-6457-4114-8613-d2f9fa9b11c5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2009q4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icXmOOF46AqF"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Then, let's get the year and quarter of the recession bottom time:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "    #Returns the year and quarter of the recession bottom time as a string value in a format such as 2005q3\n",
        "def get_recession_bottom():\n",
        "    my_gdp = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/gdplev.xls', skiprows=219)\n",
        "    my_gdp = my_gdp.iloc[:, 4:6]\n",
        "    my_gdp.columns = ['Quarter', 'GPD']\n",
        "\n",
        "    recStart = get_recession_start()\n",
        "    start_index = my_gdp[my_gdp['Quarter'] == recStart].index[0]\n",
        "    recEnd = get_recession_end()\n",
        "    end_index = my_gdp[my_gdp['Quarter'] == recEnd].index[0]\n",
        "    #slice DataFrame to select rows from start_index to end_index (inclusive) & all columns.\n",
        "    my_gdp = my_gdp.iloc[start_index:end_index + 1, :]\n",
        "    #reset index of DataFrame, dropping old index and creating a new one.\n",
        "    my_gdp = my_gdp.reset_index(drop=True)\n",
        "    #get row in DataFrame where GDP (assuming it's a column) is at its minimum.\n",
        "    #get YearQuarter value from that row to identify the bottom point of recession.\n",
        "    bottom = my_gdp.loc[my_gdp['GPD'].idxmin(), 'Quarter']\n",
        "\n",
        "    return bottom\n",
        "\n",
        "recBottom = get_recession_bottom()\n",
        "print(recBottom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "v3dGSB83tnOQ",
        "outputId": "02db76c3-9764-4693-be70-64f4c70b2a02"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2009q2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zRQxOfd6AqH"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "And then we can convert the housing data to quarters (as defined above!) and return the mean values:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}\n",
        "def year_qtr(col):\n",
        "    year_start = 0\n",
        "    year_end = 4\n",
        "\n",
        "    if col.endswith((\"01\", \"02\", \"03\")):\n",
        "        return col[year_start:year_end] + \"q1\"\n",
        "    elif col.endswith((\"04\", \"05\", \"06\")):\n",
        "        return col[year_start:year_end] + \"q2\"\n",
        "    elif col.endswith((\"07\", \"08\", \"09\")):\n",
        "        return col[year_start:year_end] + \"q3\"\n",
        "    else:\n",
        "        return col[year_start:year_end] + \"q4\"\n",
        "\n",
        "def convert_housing_data_to_quarters():\n",
        "    houses_to_quarters = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/City_Zhvi_AllHomes.csv')\n",
        "    #replace state abbreviations with full state names using 'states' dictionary\n",
        "    houses_to_quarters['State'] = houses_to_quarters['State'].replace(states)\n",
        "    #set index using 'State' & 'RegionName'\n",
        "    houses_to_quarters.set_index(['State', 'RegionName'], inplace=True, drop=False)\n",
        "    #keep columns from index 49 onwards\n",
        "    houses_to_quarters = houses_to_quarters.iloc[:, 49:]\n",
        "    houses_to_quarters = houses_to_quarters.groupby(year_qtr, axis=1).mean()\n",
        "\n",
        "    #replace NaN values with 0\n",
        "    #houses_to_quarters = houses_to_quarters.fillna(0)\n",
        "\n",
        "    houses_to_quarters.sort_index()\n",
        "    #pd.options.display.float_format = '{:.2f}'.format\n",
        "    return houses_to_quarters\n",
        "\n",
        "# Call the function to convert housing data to quarters with NaN values replaced by 0\n",
        "result = convert_housing_data_to_quarters()\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pwrIWePIv-jl",
        "outputId": "b2605142-9383-4adb-c36f-b60dba798087"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    1999q4    2000q1    2000q2    2000q3  \\\n",
            "State        RegionName                                                    \n",
            "New York     New York                  NaN       NaN       NaN       NaN   \n",
            "California   Los Angeles         201500.00 207066.67 214466.67 220966.67   \n",
            "Illinois     Chicago             135050.00 138400.00 143633.33 147866.67   \n",
            "Pennsylvania Philadelphia         52200.00  53000.00  53633.33  54133.33   \n",
            "Arizona      Phoenix             110050.00 111833.33 114366.67 116000.00   \n",
            "...                                    ...       ...       ...       ...   \n",
            "Wisconsin    Town of Wrightstown 103550.00 101766.67 105400.00 111366.67   \n",
            "New York     Urbana               77450.00  79200.00  81666.67  91700.00   \n",
            "Wisconsin    New Denmark         113900.00 114566.67 119266.67 126066.67   \n",
            "California   Angels              141850.00 151000.00 155900.00 158100.00   \n",
            "Wisconsin    Holland             149950.00 151033.33 150500.00 153233.33   \n",
            "\n",
            "                                    2000q4    2001q1    2001q2    2001q3  \\\n",
            "State        RegionName                                                    \n",
            "New York     New York                  NaN       NaN       NaN       NaN   \n",
            "California   Los Angeles         226166.67 233000.00 239100.00 245066.67   \n",
            "Illinois     Chicago             152133.33 156933.33 161800.00 166400.00   \n",
            "Pennsylvania Philadelphia         54700.00  55333.33  55533.33  56266.67   \n",
            "Arizona      Phoenix             117400.00 119600.00 121566.67 122700.00   \n",
            "...                                    ...       ...       ...       ...   \n",
            "Wisconsin    Town of Wrightstown 114866.67 125966.67 129900.00 129900.00   \n",
            "New York     Urbana               98366.67  94866.67  98533.33 102966.67   \n",
            "Wisconsin    New Denmark         131966.67 143800.00 146966.67 148366.67   \n",
            "California   Angels              167466.67 176833.33 183766.67 190233.33   \n",
            "Wisconsin    Holland             155833.33 161866.67 165733.33 168033.33   \n",
            "\n",
            "                                    2001q4    2002q1  ...    2014q2    2014q3  \\\n",
            "State        RegionName                               ...                       \n",
            "New York     New York                  NaN       NaN  ... 515466.67 522800.00   \n",
            "California   Los Angeles         253033.33 261966.67  ... 498033.33 509066.67   \n",
            "Illinois     Chicago             170433.33 175500.00  ... 192633.33 195766.67   \n",
            "Pennsylvania Philadelphia         57533.33  59133.33  ... 113733.33 115300.00   \n",
            "Arizona      Phoenix             124300.00 126533.33  ... 164266.67 165366.67   \n",
            "...                                    ...       ...  ...       ...       ...   \n",
            "Wisconsin    Town of Wrightstown 129433.33 131900.00  ... 144866.67 146866.67   \n",
            "New York     Urbana               98033.33  93966.67  ... 132133.33 137033.33   \n",
            "Wisconsin    New Denmark         149166.67 153133.33  ... 174566.67 181166.67   \n",
            "California   Angels              184566.67 184033.33  ... 244466.67 254066.67   \n",
            "Wisconsin    Holland             167400.00 165766.67  ... 201266.67 201566.67   \n",
            "\n",
            "                                    2014q4    2015q1    2015q2    2015q3  \\\n",
            "State        RegionName                                                    \n",
            "New York     New York            528066.67 532266.67 540800.00 557200.00   \n",
            "California   Los Angeles         518866.67 528800.00 538166.67 547266.67   \n",
            "Illinois     Chicago             201266.67 201066.67 206033.33 208300.00   \n",
            "Pennsylvania Philadelphia        115666.67 116200.00 117966.67 121233.33   \n",
            "Arizona      Phoenix             168500.00 171533.33 174166.67 179066.67   \n",
            "...                                    ...       ...       ...       ...   \n",
            "Wisconsin    Town of Wrightstown 149233.33 148666.67 149333.33 149866.67   \n",
            "New York     Urbana              140066.67 141700.00 137866.67 136466.67   \n",
            "Wisconsin    New Denmark         186166.67 187600.00 188666.67 188433.33   \n",
            "California   Angels              259933.33 260100.00 250633.33 263500.00   \n",
            "Wisconsin    Holland             201266.67 206000.00 207600.00 212866.67   \n",
            "\n",
            "                                    2015q4    2016q1    2016q2    2016q3  \n",
            "State        RegionName                                                   \n",
            "New York     New York            572833.33 582866.67 591633.33 587200.00  \n",
            "California   Los Angeles         557733.33 566033.33 577466.67 584050.00  \n",
            "Illinois     Chicago             207900.00 206066.67 208200.00 212000.00  \n",
            "Pennsylvania Philadelphia        122200.00 123433.33 126933.33 128700.00  \n",
            "Arizona      Phoenix             183833.33 187900.00 191433.33 195200.00  \n",
            "...                                    ...       ...       ...       ...  \n",
            "Wisconsin    Town of Wrightstown 149933.33 149833.33 151266.67 155000.00  \n",
            "New York     Urbana              136166.67 138966.67 144200.00 143000.00  \n",
            "Wisconsin    New Denmark         188933.33 191066.67 192833.33 197600.00  \n",
            "California   Angels              279500.00 276533.33 271600.00 269950.00  \n",
            "Wisconsin    Holland             217833.33 221966.67 228033.33 234950.00  \n",
            "\n",
            "[10730 rows x 68 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "  What I noticed in this section 4, is that if I replaced the NaN values here with 0's I would get a different final result in the question 5. That's why I commented out   #replace NaN values with 0\n",
        "    #houses_to_quarters = houses_to_quarters.fillna(0)"
      ],
      "metadata": {
        "id": "o8ltpY_3lbOL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MDLBck46AqI"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "Finally, let's run the actual t-test now:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "'''First creates new data showing the decline or growth of housing prices between the recession start and the recession bottom.\n",
        "Then runs a t-test comparing the university town values to the non-university towns values, return whether the alternative hypothesis (that the two groups are the same) is true or not as well as the p-value of the confidence.\n",
        "Return the tuple (different, p, better) where different=True if the t-test is True at p < 0.01 (we reject the null hypothesis), or different=False if otherwise (we cannot reject the null hypothesis).\n",
        "The variable p should be equal to the exact p value returned from scipy.stats.ttest_ind().\n",
        "The value for better should be either \"university town\" or \"non-university town\" depending on which has a lower mean price ratio (which is equivalent to a reduced market loss).\n",
        "'''\n",
        "\n",
        "def run_ttest():\n",
        "    # Retrieve the recession start and recession bottom dates\n",
        "    recStart = get_recession_start()\n",
        "    recBottom = get_recession_bottom()\n",
        "\n",
        "    # Get the list of university towns\n",
        "    university_towns = get_list_of_university_towns()\n",
        "\n",
        "    # Get the housing price data and create a new column 'price_ratio' for price change between recStart and recBottom\n",
        "    df = convert_housing_data_to_quarters()\n",
        "    university_towns['University town'] = True\n",
        "\n",
        "    df['price_ratio'] = df.loc[:, recStart] - df.loc[:, recBottom]\n",
        "\n",
        "    # Merge, replace NaN, reset index, and select columns\n",
        "    df = df.merge(university_towns, how='outer', left_index=True, right_on=['State', 'RegionName'])\n",
        "    df['University town'].fillna(False, inplace=True)\n",
        "    # Set index directly\n",
        "    df.set_index(['State', 'RegionName'], inplace=True)\n",
        "    # Select desired columns\n",
        "    df = df[['price_ratio', 'University town']]\n",
        "    # Separate data into university and non-university towns\n",
        "    university = df.loc[df['University town'], 'price_ratio']\n",
        "    non_university = df.loc[~df['University town'], 'price_ratio']\n",
        "\n",
        "    # Perform a t-test to compare the price ratios of university and non-university towns\n",
        "    t_test_result = ttest_ind(university, non_university, nan_policy='omit')\n",
        "\n",
        "    # Access the p-value from the t-test result\n",
        "    p = t_test_result.pvalue\n",
        "\n",
        "    # Check if the t-test result is statistically significant\n",
        "    different = p < 0.01\n",
        "\n",
        "    # Determine which group has a lower mean price ratio\n",
        "    if university.mean() < non_university.mean():\n",
        "        better = \"university town\"\n",
        "    else:\n",
        "        better = \"non-university town\"\n",
        "\n",
        "    return (t_test_result, p, better)\n",
        "\n",
        "# Call the function to run the t-test\n",
        "result = run_ttest()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tQRuIGHIxNR3",
        "outputId": "1ecf9a5c-d1f0-4b20-b71b-32f9a1f9047e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TtestResult(statistic=-2.8540746960114087, pvalue=0.00432521485351121, df=9882.0), 0.00432521485351121, 'university town')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}